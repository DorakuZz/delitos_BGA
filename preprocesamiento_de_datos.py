# -*- coding: utf-8 -*-
"""Preprocesamiento de datos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kinS15TODykHvDM-8qMhUTwXffv-svHL
"""

#Estas librerias sirven para hacer gráficas
import pandas as pd
import numpy as np
import seaborn as sn

#Libreria utilizada para hacer uso de URLs externas
import urllib.request

#Importar la API para el trabajo
urlvariables = "https://www.datos.gov.co/resource/x46e-abhz.csv"

variables = urllib.request.urlopen(urlvariables)

#Ese bucle for es para darle una iteración a cada línea
for linea in variables:
  #Decodificación de cada línea desde bytes a una cadena de texto utilizando UTF-8
  print(linea.decode("utf-8"))

import pandas as pd
from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')

# Especificar la ruta del archivo en tu Google Drive
url = "/content/drive/My Drive/Datos/Informaci_n_delictiva_del_municipio_de_Bucaramanga_20240925.csv"

# Leer el archivo usando el comando pd.read_csv
df = pd.read_csv(url, low_memory=False)

# Mostrar el contenido del dataframe df
df

#Ver dimensiones del dataframe
df.shape

#Este comando nos muestra la información del DataFrame
df.info()

#Ver el nombre de las columnas que están en el dataframe
df.columns

#Duplicar el dataframe para trabajar con una copia llamada dfc
dfc = df.copy()

#Este comando sirve para visualizar qué tipo de variable es cada columna
dfc.dtypes

#Con este comando podemos visualizar cuántos valores diferentes existen en cada columna
for column in dfc.columns:
    num_distinct_values = len(dfc[column].unique())
    print(f"{column}: {num_distinct_values} Valores diferentes")

#Este comando sirve para comprobar si existen filas duplicadas en el dataframe
duplicate_rows_data = dfc[dfc.duplicated()]
print("numero de filas duplicadas es: ", duplicate_rows_data.shape[0])

#Este comando sirve para comprobar si existen valores nulos
dfc.isnull().sum()

#Este comando tiene la funcion de mostrar el promedio, el mínimo, el cuartíl 1, 2 y 3 y el máximo (solo númericos)
dfc.describe().T

#Este comando tiene la funcion de mostrar el promedio, el mínimo, el cuartíl 1, 2 y 3 y el máximo (con el 'object' nos muestra los categóricos)
dfc.describe(include=['object']).T

#Con este comando podemos borrar columnas con las que no queremos trabajar
#Para borrar esas columnas se hace uso de dfc.drop("nombre_columna" axis = 1, inplace = True)
#axis = 1 significa que borra las columnas, caso diferente seria un axis = 0 que elimina filas
#inplace = True es para que se aplique en el dfc (copia) y en el df (original)
dfc.drop("AÑO_NUM", axis=1, inplace=True)
dfc.drop("CLASE_SITIO", axis=1, inplace=True)
dfc.drop("MOVIL_VICTIMA", axis=1, inplace=True)
dfc.drop("MOVIL_AGRESOR", axis=1, inplace=True)
dfc.drop("CANTIDAD_UNICA", axis=1, inplace=True)
dfc.drop("FECHA_HECHO", axis=1, inplace=True)
dfc.drop("BARRIOS_HECHO", axis=1, inplace=True)
dfc.drop("LOCALIDAD", axis = 1, inplace = True)
dfc.drop("RANGO_HORARIO", axis = 1, inplace = True)
dfc.drop("DIA_NUM", axis=1, inplace = True)
dfc.drop("CURSO_VIDA_ORDEN", axis = 1, inplace = True)
dfc.drop("CURSO_VIDA", axis = 1, inplace = True)
dfc.drop("ARTICULO", axis = 1 , inplace = True)
dfc.drop("DIA_NOMBRE_ORDEN", axis = 1, inplace = True)
dfc.drop("TIPOLOGÍA", axis = 1 , inplace = True)
dfc.drop("DELITO_SOLO" , axis = 1 , inplace = True)
dfc.drop("NUM_COM" , axis = 1, inplace = True)
dfc.drop("HORA_HECHO" , axis = 1 , inplace = True)

#Este comando tiene la función de imprimir en pantalla los nombres de las columnas del DataFrame 'dfc'
dfc.columns

#Con estos comandos podemos visualizar en nuestro terminal el nombre de cada valor único por columns
dfc.SEXO.unique()

#Con este comando podemos ver la distribución de valores en la columna
dfc.SEXO.value_counts()

#Con este comando
dfc = dfc.drop(df[df['SEXO'] == 'NO DISPONIBLE'].index)

#Con este comando podemos ver la distribución de valores en la columna
dfc.SEXO.value_counts()

dfc.EDAD.unique()

dfc.EDAD.value_counts()

import pandas as pd
import numpy as np

# Supongamos que tienes un DataFrame 'df' con una columna llamada 'edad'
dfc['EDAD'] = pd.to_numeric(df['EDAD'], errors='coerce').astype('Int32')  # Convertir a int manejando valores nulos

dfc.dtypes

dfc.describe().T

import pandas as pd
import numpy as np

# Supongamos que ya tienes el DataFrame 'df'

# Paso 1: Convertir 'NO DISPONIBLE' a NaN
dfc['EDAD'] = dfc['EDAD'].replace('NO DISPONIBLE', np.nan)

# Paso 2: Convertir la columna de 'EDAD' a numérica (en caso de que tenga valores como strings)
dfc['EDAD'] = pd.to_numeric(dfc['EDAD'], errors='coerce')

# Paso 3: Calcular la mediana de la columna 'EDAD' (ignorando los valores NaN)
median_age = dfc['EDAD'].median()

# Paso 4: Reemplazar los valores NaN (que incluyen 'nan' y 'NO DISPONIBLE') con la mediana
dfc['EDAD'] = dfc['EDAD'].fillna(median_age)

# Paso 5: Redondear la columna 'EDAD' y convertirla a int64
dfc['EDAD'] = dfc['EDAD'].round(0).astype('int64')

##Se crea la función para categorizar la columna 'EDAD'
def categorize_age(edad):
    if edad < 13:
        return 'NIÑEZ'
    elif 13 <= edad < 18:
        return 'ADOLESCENCIA'
    elif 18 <= edad < 60:
        return 'ADULTEZ'
    else:
        return 'ADULTEZ MAYOR'

# Crear la nueva columna categorizada
dfc['GATEGORIA_EDAD'] = dfc['EDAD'].apply(categorize_age)

dfc.GATEGORIA_EDAD.value_counts()

dfc.drop("EDAD", axis = 1, inplace= True)

dfc.columns

dfc.MES_NUM.value_counts()

#Se crea la función para categorizar la columna 'RANGO_HORARIO_ORDEN'
def categorize_horario(orden):
    if (0 < orden < 6):
        return 'MADRUGADA'
    elif 6 <= orden < 12:
        return 'MAÑANA'
    elif 12 <= orden < 18:
        return 'TARDE'
    else:
        return 'NOCHE'

# Crear la nueva columna categorizada
dfc['HORARIO_CATEGORIZADO'] = dfc['RANGO_HORARIO_ORDEN'].apply(categorize_horario)

dfc.drop("RANGO_HORARIO_ORDEN", axis = 1, inplace = True)

dfc.HORARIO_CATEGORIZADO.value_counts()

dfc.ARMAS_MEDIOS.value_counts()

dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('VEHICULO', 'VEHICULO')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('MOTO', 'VEHICULO')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('BICICLETA', 'VEHICULO')

dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('GRANADA DE MANO', 'EXPLOSIVO')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('PAPA EXPLOSIVA', 'EXPLOSIVO')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('COMBUSTIBLE', 'EXPLOSIVO')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ARTEFACTO EXPLOSIVO/CARGA DINAMITA', 'EXPLOSIVO')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ARTEFACTO INCENDIARIO', 'EXPLOSIVO')

dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ARMA BLANCA / CORTOPUNZANTE', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ARMA DE FUEGO', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('CONTUNDENTES', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('CUERDA/SOGA/CADENA', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('CORTANTES', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ARMA TRAUMATICA', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('PUNZANTES', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('CORTOPUNZANTES', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('LLAVE MAESTRA', 'ARMAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('PALANCAS', 'ARMAS')

dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ESCOPOLAMINA', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('ACIDO', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('AGUA CALIENTE', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('QUIMICOS', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('GASES', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('SUSTANCIAS TOXICAS', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('LICOR ADULTERADO', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('VENENO', 'SUSTANCIAS QUIMICAS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('MEDICAMENTOS', 'SUSTANCIAS QUIMICAS')

dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('JERINGA', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('PRENDAS DE VESTIR', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('REDES SOCIALES', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('NO REPORTADO', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('NO DISPONIBLE', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('MIXTA', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('LLAMADA TELEFONICA', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('CARTA EXTORSIVA', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('DIRECTA', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('PERRO', 'OTROS')
dfc['ARMAS_MEDIOS'] = dfc['ARMAS_MEDIOS'].replace('BOLSA PLASTICA', 'OTROS')

dfc.ARMAS_MEDIOS.value_counts()

dfc.DESCRIPCION_CONDUCTA.unique()

import pandas as pd

# Supón que tienes tu DataFrame dfc cargado
# dfc = pd.read_csv("ruta_del_archivo.csv")

# Definir el mapeo de categorías
mapeo_conductas = {
    'HURTO': [
        'ARTÍCULO 239. HURTO PERSONAS', 'ARTÍCULO 239. HURTO RESIDENCIAS',
        'ARTÍCULO 239. HURTO MOTOCICLETAS', 'ARTÍCULO 239. HURTO AUTOMOTORES',
        'ARTÍCULO 243. ABIGEATO', 'ARTÍCULO 243. HURTO ABIGEATO'
    ],
    'DELITOS SEXUALES': [
        'ARTÍCULO 209. ACTOS SEXUALES CON MENOR DE 14 AÑOS',
        'ARTÍCULO 208. ACCESO CARNAL ABUSIVO CON MENOR DE 14 AÑOS',
        'ARTÍCULO 206. ACTO SEXUAL VIOLENTO',
        'ARTÍCULO 219 A. UTILIZACIÓN O FACILITACIÓN DE MEDIOS DE COMUNICACIÓN PARA OFRECER SERVICIOS SEXUALES DE MENORES',
        'ARTÍCULO 205. ACCESO CARNAL VIOLENTO',
        'ARTÍCULO 211. ACCESO CARNAL O ACTO SEXUAL EN PERSONA PUESTA EN INCAPACIDAD DE RESISTIR (CIRCUNSTANCIAS AGRAVACIÓN)',
        'ARTÍCULO 207. ACCESO CARNAL O ACTO SEXUAL EN PERSONA PUESTA EN INCAPACIDAD DE RESISTIR',
        'ARTÍCULO 210 A. ACOSO SEXUAL',
        'ARTÍCULO 217 A. DEMANDA DE EXPLOTACION SEXUAL COMERCIAL DE PERSONA MENOR DE 18 AÑOS DE EDAD',
        'ARTÍCULO 217. ESTÍMULO A LA PROSTITUCIÓN DE MENORES',
        'ARTÍCULO 214. CONSTREÑIMIENTO A LA PROSTITUCIÓN',
        'ARTÍCULO 210. ACCESO CARNAL O ACTO SEXUAL ABUSIVO CON INCAPAZ DE RESISTIR',
        'ARTÍCULO 218. PORNOGRAFÍA CON MENORES',
        'ARTÍCULO 213 A. PROXENETISMO CON MENOR DE EDAD'
    ],
    'VIOLENCIA INTRAFAMILIAR': [
        'ARTÍCULO 229. VIOLENCIA INTRAFAMILIAR'
    ],
    'LESIONES': [
        'ARTÍCULO 120. LESIONES CULPOSAS', 'ARTÍCULO 120. LESIONES CULPOSAS ( EN ACCIDENTE DE TRANSITO )',
        'ARTÍCULO 125. LESIONES AL FETO', 'ARTÍCULO 111. LESIONES PERSONALES'
    ],
    'HOMICIDIO': [
        'ARTÍCULO 103. HOMICIDIO', 'ARTÍCULO 104A. FEMINICIDIO',
        'ARTÍCULO 109. HOMICIDIO CULPOSO ( EN ACCIDENTE DE TRÁNSITO)'
    ],
    'EXTORSIÓN': [
        'ARTÍCULO 244. EXTORSIÓN'
    ],
    'AMENAZAS': [
        'ARTÍCULO 347. AMENAZAS'
    ]
}

# Reemplazar los valores en la columna 'DESCRIPCION_CONDUCTA'
dfc['DESCRIPCION_CONDUCTA'] = dfc['DESCRIPCION_CONDUCTA'].replace({
    valor: categoria
    for categoria, valores in mapeo_conductas.items()
    for valor in valores
})

# Mostrar el DataFrame actualizado
print(dfc['DESCRIPCION_CONDUCTA'])

dfc.dtypes

dfc.isnull().sum()

from sklearn.preprocessing import OrdinalEncoder

# Definir el orden de las categorías
SEXO = [['MASCULINO', 'FEMENINO']]

# Crear y ajustar el codificador
codificar_sexo = OrdinalEncoder(categories=SEXO)
codificador_sexo = codificar_sexo.fit(dfc[['SEXO']])

# Transformar los datos
sexo_transformada = codificador_sexo.transform(dfc[['SEXO']])

# Mostrar el resultado
print(sexo_transformada)

from sklearn.preprocessing import OrdinalEncoder

# Definir el orden de las categorías
DIA_NOMBRE = [['lunes', 'martes', 'miércoles', 'jueves', 'viernes', 'sábado', 'domingo']]

# Crear y ajustar el codificador
codificar_dia = OrdinalEncoder(categories=DIA_NOMBRE)
codificador_dia = codificar_dia.fit(dfc[['DIA_NOMBRE']])

# Transformar los datos
dia_transformada = codificador_dia.transform(dfc[['DIA_NOMBRE']])

# Mostrar el resultado
print(dia_transformada)

from sklearn.preprocessing import OrdinalEncoder

# Definir el orden de las categorías
NOM_COMUNA = [['SUR', 'PROVENZA', 'LA CIUDADELA', 'LA CONCORDIA', 'CENTRO',
       'CABECERA DEL LLANO', 'ORIENTAL', 'OCCIDENTAL', 'SAN FRANCISCO',
       'NORORIENTAL', 'NORTE', 'SUROCCIDENTE', 'GARCIA ROVIRA',
       'MORRORICO', 'LA PEDREGOSA', 'MUTIS', 'LAGOS DEL CACIQUE',
       'NO DISPONIBLE', 'CORREGIMIENTO 1', 'CORREGIMIENTO 3',
       'CORREGIMIENTO 2']]

# Crear y ajustar el codificador
codificar_comuna = OrdinalEncoder(categories=NOM_COMUNA)
codificador_comuna = codificar_comuna.fit(dfc[['NOM_COM']])

# Transformar los datos
comuna_transformada = codificador_comuna.transform(dfc[['NOM_COM']])

# Mostrar el resultado
print(comuna_transformada)

dfc.columns

df_modelo = pd.get_dummies(dfc, columns=['SEXO','ARMAS_MEDIOS','GATEGORIA_EDAD','HORARIO_CATEGORIZADO', 'DIA_NOMBRE','NOM_COM'
    ], drop_first=True)

df_modelo.info()

df_modelo.columns

from sklearn.model_selection import train_test_split
X = df_modelo.drop(columns=['DESCRIPCION_CONDUCTA'])  # Eliminar la columna objetivo
y = df_modelo['DESCRIPCION_CONDUCTA']  # La columna objetivo
# Dividir en conjuntos de entrenamiento y prueba (80% para entrenamiento y 20% para prueba)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(X_train.dtypes)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12345)

print(X_train.dtypes)

from sklearn.model_selection import train_test_split
import pandas as pd
from sklearn.linear_model import LogisticRegression # import the model

X = pd.get_dummies(df_modelo.drop(columns=['DESCRIPCION_CONDUCTA']), drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

modelo = LogisticRegression() # create an instance of the model and assign it to the variable "modelo"
modelo.fit(X_train, y_train)
from sklearn.metrics import accuracy_score, classification_report

# Predecir los valores en el conjunto de prueba
y_pred = modelo.predict(X_test)
# Calcular la precisión
precision = accuracy_score(y_test, y_pred)
print(f'Precisión del modelo: {precision:.2f}')

# Generar un informe detallado de clasificación
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report
import joblib  # Biblioteca para guardar el modelo en formato binario

# Definir el modelo
modelo = RandomForestClassifier(random_state=42)

# Definir la cuadrícula de parámetros
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
}

# Crear el GridSearchCV
grid_search = GridSearchCV(estimator=modelo, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Entrenar el modelo
grid_search.fit(X_train, y_train)

# Ver los mejores parámetros
print("Mejores parámetros:", grid_search.best_params_)

# Usar el mejor modelo
mejor_modelo = grid_search.best_estimator_

# Predecir los valores en el conjunto de prueba
y_pred = mejor_modelo.predict(X_test)

# Calcular la precisión
precision = accuracy_score(y_test, y_pred)
print(f'Precisión del modelo: {precision:.2f}')

# Generar un informe detallado de clasificación
print(classification_report(y_test, y_pred))

# Guardar el modelo en un archivo .bin usando joblib
modelo_usar = 'mejor_modelo_random_forest.bin'
joblib.dump(mejor_modelo, modelo_usar)

print(f'Modelo guardado como {modelo_usar}')